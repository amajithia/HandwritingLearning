# -*- coding: utf-8 -*-
"""dataloader_ICDAR17_words.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Gq804iVGcxAMEXkWZLo5vlChErUS_UcS
"""

import os
import pickle
import numpy as np
from PIL import Image
from scipy import misc
import torch.utils.data as data
import torch
from torchvision.transforms import Compose, ToTensor
import random

class DatasetFromFolder(data.Dataset):
    def __init__(self, dataset, foldername, labelfolder, imgtype='png', scale_size=(64, 128), is_training=True):
        super(DatasetFromFolder, self).__init__()

        self.is_training = is_training
        self.imgtype = imgtype
        self.scale_size = scale_size
        self.folder = foldername
        self.dataset = dataset

        if self.dataset == 'CERUG-EN':
            self.cerug = True
        else:
            self.cerug = False

        # Path to the writer index table
        self.labelidx_name = 'ICDAR17_lsegsICDAR17_lsegswriter_index_table.pickle'

        # Load image list and writer identities
        self.imglist = self._get_image_list(self.folder)
        self.idlist = self._get_all_identity()
        self.idx_tab = self._convert_identity2index(self.labelidx_name)

        self.num_writer = len(self.idx_tab)  # Number of unique writers

        # Print dataset information
        print('-' * 10)
        print(f'Loading dataset {dataset} with images: {len(self.imglist)}')
        print(f'Number of writers: {len(self.idx_tab)}')
        print('-*' * 10)

    def _convert_identity2index(self, savename):
        if os.path.exists(savename):
            # Load existing writer index table
            with open(savename, 'rb') as fp:
                identity_idx = pickle.load(fp)
        else:
            # Create new writer index table
            identity_idx = {ids: idx for idx, ids in enumerate(self.idlist)}
            with open(savename, 'wb') as fp:
                pickle.dump(identity_idx, fp)

        return identity_idx

    def _get_all_identity(self):
        # Extract all unique writer identities from image filenames
        writer_list = [self._get_identity(img) for img in self.imglist]
        return list(set(writer_list))

    def _get_identity(self, fname):
        # Extract writer identity from filename based on dataset type
        return fname.split('_')[0] if self.cerug else fname.split('-')[0]

    def _get_image_list(self, folder):
        # Get list of image files in the folder with the specified type
        flist = os.listdir(folder)
        return [img for img in flist if img.endswith(self.imgtype)]

    def transform(self):
        # Transform image to tensor
        return Compose([ToTensor()])

    def resize(self, image):
        # Resize image while maintaining aspect ratio
        w, h = image.size[:2]
        ratio_h = float(self.scale_size[0]) / float(h)
        ratio_w = float(self.scale_size[1]) / float(w)

        ratio = min(ratio_h, ratio_w)
        nh, nw = int(ratio * h), int(ratio * w)

        imre = image.resize((nw, nh))
        im_array = 255 - np.array(imre)
        imre = Image.fromarray(im_array)

        # Verify image integrity
        if imre is None or not isinstance(imre, Image.Image):
            raise ValueError("Invalid image data.")
        try:
            imre.verify()
        except Exception as e:
            raise ValueError("Corrupted image data.") from e

        # Center the resized image on a black background
        new_img = np.zeros(self.scale_size)
        dy = random.randint(0, self.scale_size[0] - nh) if self.is_training else (self.scale_size[0] - nh) // 2
        dx = random.randint(0, self.scale_size[1] - nw) if self.is_training else (self.scale_size[1] - nw) // 2

        imre = imre.convert('F')
        new_img[dy:dy + nh, dx:dx + nw] = imre

        return new_img, ratio_h < ratio_w

    def __getitem__(self, index):
        # Get image and corresponding writer index
        imgfile = self.imglist[index]
        writer = self.idx_tab[self._get_identity(imgfile)]

        image = Image.open(self.folder + imgfile).convert('L')
        image, _ = self.resize(image)
        image = self.transform()(image / 255.0)
        writer = torch.from_numpy(np.array(writer))

        return image, writer, imgfile

    def __len__(self):
        # Return the number of images in the dataset
        return len(self.imglist)